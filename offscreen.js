console.log("🔍 OFFSCREEN DEBUG: RAG SCRIPT LOADING STARTED...");console.log("🔍 OFFSCREEN DEBUG: Date:",new Date().toISOString());try{chrome.runtime.sendMessage({type:"LOCAL_AI_STATUS",status:"Offscreen script loading...",progress:1,ready:!1}),console.log("🔍 OFFSCREEN DEBUG: Initial status message sent")}catch(e){console.log("🔍 OFFSCREEN DEBUG: Failed to send initial status:",e)}console.log("🔍 OFFSCREEN DEBUG: Basic script execution working");try{chrome.runtime.sendMessage({type:"LOCAL_AI_STATUS",status:"Offscreen HTML loaded!",progress:.5,ready:!1}),console.log("🔍 OFFSCREEN DEBUG: HTML status message sent")}catch(e){console.log("🔍 OFFSCREEN DEBUG: Failed to send HTML status:",e)}let y,M,A=!1,E=!1;console.log("🔍 OFFSCREEN DEBUG: Setting up Web Worker for transformers.js...");const D=document.getElementById("status"),O=document.getElementById("progressBar"),U=document.getElementById("details");function s(e,t=null,o=null){D&&(D.textContent=e),t!==null&&O&&(O.style.width=`${t}%`),o&&U&&(U.textContent=o),e&&e.includes("Loading")&&e.includes("model")&&(k(),v(e)),chrome.runtime.sendMessage({type:"LOCAL_AI_STATUS",status:e,progress:t,ready:E})}function k(){const e=document.getElementById("modelProgress"),t=document.getElementById("downloadInfo");e&&e.style.display==="none"&&(e.style.display="block",t&&(t.style.display="block"))}function v(e,t){const o={classifier:{element:"scout",name:"Scout",emoji:"🔍"},embedding:{element:"indexer",name:"Indexer",emoji:"📊"},NER:{element:"extractor",name:"Extractor",emoji:"🏷️"},generative:{element:"synthesizer",name:"Synthesizer",emoji:"✨"}};let n=null;for(const[i,l]of Object.entries(o))if(e.toLowerCase().includes(i.toLowerCase())){n=l;break}if(n){const i=document.getElementById(`${n.element}Progress`),l=document.getElementById(`${n.element}Status`);i&&l&&(e.includes("Loading")?(i.style.width="50%",l.textContent="Downloading...",l.className="model-status downloading"):e.includes("loaded")&&(i.style.width="100%",l.textContent="Ready ✅",l.className="model-status complete"))}}let R=null,x=!1;function N(){console.log("🔍 OFFSCREEN DEBUG: Creating transformers.js Web Worker (local build)...");try{R=new Worker(chrome.runtime.getURL("transformers-worker.js")),R.onmessage=function(t){const o=t.data,{type:n}=o;switch(n){case"status":s(o.message,o.progress);break;case"init-complete":o.success?(console.log("🔍 OFFSCREEN DEBUG: All AI models initialized successfully!"),x=!0,E=!0,s("All AI models ready! ✅",100)):(console.error("🔍 OFFSCREEN DEBUG: AI model initialization failed:",o.error),p(new Error(o.error)));break;case"error":console.error("🔍 OFFSCREEN DEBUG: Worker error:",o.error),p(new Error(o.error||"Unknown worker error"));break;case"classify-result":case"embed-result":case"entities-result":case"generate-result":T(o);break;default:console.log("🔍 OFFSCREEN DEBUG: Unknown worker message:",n)}},R.onerror=function(t){console.error("🔍 OFFSCREEN DEBUG: Worker error:",t),p(t)};const e=chrome.runtime.getURL("/");console.log("🔍 OFFSCREEN DEBUG: Extension base URL:",e),s("Initializing AI models...",5),R.postMessage({type:"init",data:{extensionBaseURL:e}})}catch(e){console.error("🔍 OFFSCREEN DEBUG: Failed to create Web Worker:",e),p()}}function p(e){console.log("🔍 OFFSCREEN DEBUG: Transformers.js Web Worker failed, falling back to browser-native approach..."),s("Transformers.js incompatible, using browser-native approach...",10),$()}function T(e){const{type:t,id:o}=e;switch(t){case"classify-result":console.log("🔍 OFFSCREEN DEBUG: Received classification result for ID:",o);break;case"embed-result":console.log("🔍 OFFSCREEN DEBUG: Received embedding result for ID:",o);break;case"entities-result":console.log("🔍 OFFSCREEN DEBUG: Received entities result for ID:",o);break;case"generate-result":console.log("🔍 OFFSCREEN DEBUG: Received generation result for ID:",o);break;default:console.log("🔍 OFFSCREEN DEBUG: Unknown AI result type:",t)}}try{chrome.runtime.sendMessage({type:"LOCAL_AI_STATUS",status:"Setting up transformers.js...",progress:2,ready:!1})}catch(e){console.log("🔍 OFFSCREEN DEBUG: Failed to send setup status:",e)}console.log("🔍 OFFSCREEN DEBUG: Starting Web Worker transformers.js loading...");try{chrome.runtime.sendMessage({type:"LOCAL_AI_STATUS",status:"Starting Web Worker approach...",progress:3,ready:!1})}catch(e){console.log("🔍 OFFSCREEN DEBUG: Failed to send Web Worker status:",e)}document.readyState==="loading"?document.addEventListener("DOMContentLoaded",N):N();async function $(){console.log("🔍 OFFSCREEN DEBUG: Initializing browser-native RAG system...");try{s("Setting up browser-native AI...",15,"Initializing simple embedding system"),await I(),y=_(),M={allowRemoteModels:!0,allowLocalModels:!1},A=!0,g=!0,E=!0,console.log("🔍 OFFSCREEN DEBUG: Browser-native RAG system ready");try{chrome.runtime.sendMessage({type:"LOCAL_AI_STATUS",status:"Browser-native AI ready!",progress:50,ready:!0})}catch(e){console.log("🔍 OFFSCREEN DEBUG: Failed to send ready status:",e)}s("Browser-native AI Ready! ✅",50,"Simple embedding system loaded"),u=!1}catch(e){throw console.error("🔍 OFFSCREEN DEBUG: Browser-native RAG initialization failed:",e),s("❌ Browser-native AI failed",0,e.message),e}}function _(){return console.log("🔍 OFFSCREEN DEBUG: Creating simple embedder..."),async(e,t={})=>(console.log("🔍 OFFSCREEN DEBUG: Generating simple embedding for text length:",e.length),{data:z(e)})}function z(e,t=256){const o=e.toLowerCase().replace(/[^\w\s]/g," ").trim(),n=o.split(/\s+/).filter(r=>r.length>2),i=new Array(t).fill(0);for(let r=0;r<Math.min(26,t);r++){const a=String.fromCharCode(97+r),c=(o.match(new RegExp(a,"g"))||[]).length;i[r]=c/o.length}if(t>26){const r=new Array(10).fill(0);n.forEach(a=>{const c=Math.min(9,Math.floor(a.length/2));r[c]++});for(let a=0;a<Math.min(10,t-26);a++)i[26+a]=r[a]/n.length}if(t>36)for(let r=36;r<t;r++){let a=0;for(let c=0;c<o.length;c++)a=(a<<5)-a+o.charCodeAt(c)&4294967295;i[r]=a%1e3/1e3}const l=Math.sqrt(i.reduce((r,a)=>r+a*a,0));if(l>0)for(let r=0;r<i.length;r++)i[r]/=l;return i}function P(e,t){if(t.length===0)return`I couldn't find any relevant information for: "${e}". Please try a different question or check if documents have been indexed.`;const o=e.toLowerCase().split(/\s+/),n=e.includes("?")||o.some(d=>["what","how","why","when","where","who","which"].includes(d)),i=o.some(d=>["compare","difference","versus","vs","better","worse"].includes(d)),l=o.some(d=>["define","meaning","what is","definition"].includes(d)),r=[];t.forEach((d,m)=>{d.text.split(/[.!?]+/).filter(S=>S.trim().length>10).forEach(S=>{const B=S.toLowerCase();o.some(L=>B.includes(L))&&r.push({text:S.trim(),source:m+1,relevance:W(B,o)})})}),r.sort((d,m)=>m.relevance-d.relevance);const a=r.slice(0,3);let c="";return l&&a.length>0?(c=`Based on the documents:

${a[0].text}`,a.length>1&&(c+=`

Additionally: ${a[1].text}`)):i&&t.length>1?(c=`I found information about "${e}" in ${t.length} different sections:

`,t.slice(0,2).forEach((d,m)=>{const C=d.text.substring(0,150)+"...";c+=`**Source ${m+1}:** ${C}

`})):a.length>0?(n?c=`Regarding "${e}":

`:c=`I found relevant information about "${e}":

`,a.forEach((d,m)=>{m===0?c+=d.text:c+=`

Additionally: ${d.text}`})):(c=`I found ${t.length} potentially relevant sections for "${e}", but couldn't extract specific answers. `,c+=`The most relevant content begins with: "${t[0].text.substring(0,100)}..."`),c+=`

*This response was generated using browser-native text processing from ${t.length} relevant document sections.*`,c}function W(e,t){let o=0;return t.forEach(n=>{if(n.length>2){const i=(e.match(new RegExp(n,"g"))||[]).length;o+=i*n.length}}),o}let w=null,b=null,F=!1,h=!1,g=!1,u=!1,f=null;async function j(){if(console.log("🔍 OFFSCREEN DEBUG: initializeModel called"),console.log("🔍 OFFSCREEN DEBUG: Embedder status - loading:",F,"ready:",g),console.log("🔍 OFFSCREEN DEBUG: Generator status - loading:",h,"ready:",u),(F||g)&&(h||u)){console.log("🔍 OFFSCREEN DEBUG: Models already loading or ready, returning early");return}if(!y){console.log("🔍 OFFSCREEN DEBUG: Transformers.js not loaded yet, waiting..."),s("Waiting for transformers.js...",5,"Loading dependencies");for(let e=0;e<20;e++){if(y){console.log("🔍 OFFSCREEN DEBUG: Transformers.js now available, proceeding");break}await new Promise(t=>setTimeout(t,500))}if(!y)throw new Error("Transformers.js failed to load after 10 seconds")}try{await I(),!g&&!F&&await H(),!u&&!h&&await Y(),console.log("🔍 OFFSCREEN DEBUG: RAG system fully initialized!"),s("Model Ready! ✅",100,"EmbeddingGemma loaded successfully"),E=!0,isLoading=!1,console.log("EmbeddingGemma model initialized successfully")}catch(e){console.error("Failed to initialize EmbeddingGemma:",e),s("❌ Failed to load model",0,`Error: ${e.message}`),isLoading=!1,chrome.runtime.sendMessage({type:"LOCAL_AI_ERROR",error:e.message})}}async function H(){F=!0,console.log("🔍 OFFSCREEN DEBUG: Loading embedding model...");try{s("Loading Embedding Model...",20,"Downloading google/embeddinggemma-300m"),w=await y("feature-extraction","google/embeddinggemma-300m",{progress_callback:e=>{if(e.status==="downloading"){const t=Math.round(e.loaded/e.total*100);console.log(`🔍 OFFSCREEN DEBUG: Embedding model progress: ${t}% - ${e.name}`),s(`Loading embedding model: ${e.name}`,20+t*.3,`Downloaded ${Math.round(e.loaded/1024/1024)}MB / ${Math.round(e.total/1024/1024)}MB`)}}}),g=!0,F=!1,console.log("🔍 OFFSCREEN DEBUG: Embedding model loaded successfully"),s("Embedding Model Ready ✅",50,"Now loading generative model...")}catch(e){throw F=!1,console.error("🔍 OFFSCREEN DEBUG: Failed to load embedding model:",e),e}}async function Y(){h=!0,console.log("🔍 OFFSCREEN DEBUG: Loading generative model...");try{s("Loading Generative Model...",50,"Downloading Xenova/gemma-2b-it"),b=await y("text-generation","Xenova/gemma-2b-it",{progress_callback:e=>{if(e.status==="downloading"){const t=Math.round(e.loaded/e.total*100);console.log(`🔍 OFFSCREEN DEBUG: Generative model progress: ${t}% - ${e.name}`),s(`Loading generative model: ${e.name}`,50+t*.4,`Downloaded ${Math.round(e.loaded/1024/1024)}MB / ${Math.round(e.total/1024/1024)}MB`)}}}),u=!0,h=!1,console.log("🔍 OFFSCREEN DEBUG: Generative model loaded successfully"),s("RAG System Ready! ✅",100,"Both models loaded - ready for document processing")}catch(e){h=!1,console.error("🔍 OFFSCREEN DEBUG: Failed to load generative model:",e),s("Embedding Ready (Generator Failed)",50,"Can create embeddings but not generate text")}}async function I(){console.log("🔍 OFFSCREEN DEBUG: Initializing vector storage...");try{s("Setting up vector storage...",10,"Initializing IndexedDB"),f={store:async(e,t,o)=>{console.log("🔍 OFFSCREEN DEBUG: Storing vectors for document:",e)},search:async(e,t=5)=>(console.log("🔍 OFFSCREEN DEBUG: Searching for similar vectors"),[]),list:async()=>[]},console.log("🔍 OFFSCREEN DEBUG: Vector storage initialized"),s("Vector storage ready",15,"IndexedDB initialized")}catch(e){throw console.error("🔍 OFFSCREEN DEBUG: Failed to initialize vector storage:",e),e}}async function G(e){if(!E||!w)throw new Error("Model not ready. Please initialize first.");try{s("Processing text...",null,`Generating embedding for ${e.length} characters`);const t=Date.now(),o=await w(e,{pooling:"mean",normalize:!0}),n=Date.now()-t;return s("Model Ready! ✅",100,`Processed in ${n}ms`),Array.from(o.data)}catch(t){throw console.error("Error generating embedding:",t),s("Model Ready! ✅",100,"Ready for processing"),t}}async function K(e,t={}){if(!g)throw new Error("Embedding model not ready");try{console.log("🔍 OFFSCREEN DEBUG: Starting RAG pipeline for query:",e),s("Processing query...",null,"Generating query embedding");const o=await G(e);console.log("🔍 OFFSCREEN DEBUG: Query embedding generated"),s("Searching documents...",null,"Finding relevant context");const n=await f.search(o,t.topK||3);console.log("🔍 OFFSCREEN DEBUG: Found relevant chunks:",n.length);const i=n.map(l=>l.text).join(`

`);if(u&&b){s("Generating response...",null,"Using Gemma-2b-it for text generation");const l=V(e,i,t);console.log("🔍 OFFSCREEN DEBUG: Generated RAG prompt length:",l.length);const r=await b(l,{max_new_tokens:t.maxTokens||256,temperature:t.temperature||.7,do_sample:!0,top_p:.9});return s("Response generated ✅",null,"RAG pipeline complete"),{response:r[0].generated_text.replace(l,"").trim(),sources:n.map(a=>({id:a.docId,snippet:a.text.substring(0,100)+"..."})),query:e,context:i.substring(0,500)+"..."}}else return console.log("🔍 OFFSCREEN DEBUG: Using browser-native response mode"),s("Browser-native response",null,"Generating structured response"),{response:P(e,n),sources:n.map(r=>({id:r.docId,snippet:r.text.substring(0,200)+"..."})),query:e,context:i.substring(0,1e3)+"...",mode:"browser-native"}}catch(o){throw console.error("🔍 OFFSCREEN DEBUG: Error in RAG pipeline:",o),s("RAG pipeline error",null,o.message),o}}function V(e,t,o={}){return`${o.systemPrompt||"You are a helpful AI assistant that answers questions based on provided context. Use only the information from the context to answer questions. If the context doesn't contain relevant information, say so clearly."}

Context:
${t}

Question: ${e}

Answer:`}async function Q(e,t,o={}){if(console.log("🔍 OFFSCREEN DEBUG: Processing document:",e),!g)throw new Error("Embedding model not ready for document processing");try{s("Processing document...",null,`Chunking text for ${e}`);const n=X(t,o.chunkSize||512,o.chunkOverlap||50);console.log("🔍 OFFSCREEN DEBUG: Created chunks:",n.length),s("Generating embeddings...",null,`Processing ${n.length} chunks`);const i=[];for(let l=0;l<n.length;l++){const r=await G(n[l]);i.push(r);const a=Math.round((l+1)/n.length*100);s(`Embedding chunks... ${l+1}/${n.length}`,null,`${a}% complete`)}return await f.store(e,n,i),s("Document processed ✅",null,`${n.length} chunks indexed`),{docId:e,chunks:n.length,success:!0}}catch(n){throw console.error("🔍 OFFSCREEN DEBUG: Error processing document:",n),n}}function X(e,t=512,o=50){const n=[],i=e.split(/\s+/);for(let l=0;l<i.length;l+=t-o){const r=i.slice(l,l+t).join(" ");r.trim().length>0&&n.push(r.trim())}return n}chrome.runtime.onMessage.addListener((e,t,o)=>{switch(console.log("🔍 OFFSCREEN DEBUG: Received message:",e.type,e),e.type){case"INIT_LOCAL_AI":return console.log("🔍 OFFSCREEN DEBUG: Starting model initialization..."),j().then(()=>{console.log("🔍 OFFSCREEN DEBUG: Model initialization completed, isReady:",E),o({success:!0,ready:E})}).catch(n=>{console.log("🔍 OFFSCREEN DEBUG: Model initialization failed:",n.message),o({success:!1,error:n.message})}),!0;case"GENERATE_EMBEDDING":return g?G(e.text).then(n=>o({success:!0,embedding:n})).catch(n=>o({success:!1,error:n.message})):o({success:!1,error:"Embedding model not ready"}),!0;case"GENERATE_RESPONSE":return g?K(e.query,e.options||{}).then(n=>o({success:!0,response:n})).catch(n=>o({success:!1,error:n.message})):o({success:!1,error:"RAG system not ready"}),!0;case"PROCESS_DOCUMENT":return g?Q(e.docId,e.text,e.options||{}).then(n=>o({success:!0,result:n})).catch(n=>o({success:!1,error:n.message})):o({success:!1,error:"Embedding model not ready for document processing"}),!0;case"LIST_DOCUMENTS":return f?f.list().then(n=>o({success:!0,documents:n})).catch(n=>o({success:!1,error:n.message})):o({success:!1,error:"Vector store not initialized"}),!0;case"CHECK_STATUS":o({embedderReady:g,generatorReady:u,embedderLoading:F,generatorLoading:h,vectorStoreReady:!!f,ragReady:g&&!!f});break;case"CHECK_LOCAL_AI_STATUS":o({ready:E,embedderReady:g,generatorReady:u,transformersLoaded:A,status:E?"Ready":"Not ready"});break;default:console.log("Unknown message type:",e.type)}});s("Ready to load model",0,'Click "Setup Local AI" to begin');console.log("🔍 OFFSCREEN DEBUG: Document ready, sending OFFSCREEN_READY message...");chrome.runtime.sendMessage({type:"OFFSCREEN_READY"}).then(()=>{console.log("🔍 OFFSCREEN DEBUG: OFFSCREEN_READY message sent successfully")}).catch(e=>{console.log("🔍 OFFSCREEN DEBUG: Failed to send OFFSCREEN_READY:",e)});console.log("🔍 OFFSCREEN DEBUG: Branestawm offscreen document loaded and ready for messages");console.log("🔍 OFFSCREEN DEBUG: Auto-initialization will trigger after transformers.js loads");
