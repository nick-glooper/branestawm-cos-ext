console.log("ğŸ” WORKER: Transformers.js worker starting (local build)...");let r=null,a=null,i=null,l=null,s=null;self.addEventListener("message",async d=>{const{type:t,data:e}=d.data;console.log(`ğŸ” WORKER: Received message: ${t}`);try{if(t==="init"){console.log("ğŸ” WORKER: Initializing AI models...");const o=e.extensionBaseURL;console.log("ğŸ” WORKER: Extension base URL:",o);try{console.log("ğŸ” WORKER: Loading local transformers.js..."),s=await import(o+"transformers.js"),console.log("ğŸ” WORKER: Local transformers.js loaded successfully!")}catch(n){console.error("ğŸ” WORKER: Failed to load local transformers.js:",n),postMessage({type:"init-complete",success:!1,error:"Failed to load transformers.js: "+n.message});return}typeof s<"u"&&s.env&&(s.env.backends.onnx.wasm.wasmPaths=o,s.env.backends.onnx.wasm.numThreads=1,s.env.backends.onnx.wasm.simd=!0,s.env.allowRemoteModels=!0,s.env.allowLocalModels=!1,s.env.remoteHost="https://huggingface.co/",s.env.remotePathTemplate="{model}/resolve/main/",console.log("ğŸ” WORKER: Transformers.js configured for single-threaded CSP-compatible operation"),console.log("ğŸ” WORKER: ONNX threads:",s.env.backends.onnx.wasm.numThreads),console.log("ğŸ” WORKER: Remote host:",s.env.remoteHost));try{postMessage({type:"status",message:"Loading classifier model...",progress:20}),console.log("ğŸ” WORKER: Loading classifier (The Scout)..."),r=await s.pipeline("zero-shot-classification","Xenova/distilbert-base-uncased-mnli",{session_options:{executionProviders:["wasm"]}}),console.log("ğŸ” WORKER: Classifier loaded"),postMessage({type:"status",message:"Loading embedding model...",progress:40}),console.log("ğŸ” WORKER: Loading embedder (The Indexer)..."),a=await s.pipeline("feature-extraction","Xenova/all-MiniLM-L6-v2",{session_options:{executionProviders:["wasm"]}}),console.log("ğŸ” WORKER: Embedder loaded"),postMessage({type:"status",message:"Loading NER model...",progress:60}),console.log("ğŸ” WORKER: Loading NER extractor (The Extractor)..."),i=await s.pipeline("ner","Xenova/distilbert-base-multilingual-cased-ner-hrl",{session_options:{executionProviders:["wasm"]}}),console.log("ğŸ” WORKER: NER extractor loaded"),postMessage({type:"status",message:"Loading generative model...",progress:80}),console.log("ğŸ” WORKER: Loading generator (The Synthesizer)..."),l=await s.pipeline("text-generation","Xenova/Gemma-2-2B-it",{session_options:{executionProviders:["wasm"]}}),console.log("ğŸ” WORKER: Generator loaded"),postMessage({type:"init-complete",success:!0,progress:100}),console.log("ğŸ” WORKER: All AI models initialized successfully!")}catch(n){console.error("ğŸ” WORKER: Model initialization failed:",n),postMessage({type:"init-complete",success:!1,error:n.message})}}else if(t==="classify"){if(!r)throw new Error("Classifier not initialized");console.log("ğŸ” WORKER: Running classification...");const o=await r(e.text,e.labels);postMessage({type:"classify-result",id:e.id,result:o})}else if(t==="embed"){if(!a)throw new Error("Embedder not initialized");console.log("ğŸ” WORKER: Generating embedding...");const o=await a(e.text);postMessage({type:"embed-result",id:e.id,embedding:o.data})}else if(t==="extract_entities"){if(!i)throw new Error("NER extractor not initialized");console.log("ğŸ” WORKER: Extracting entities...");const o=await i(e.text);postMessage({type:"entities-result",id:e.id,entities:o})}else if(t==="generate"){if(!l)throw new Error("Generator not initialized");console.log("ğŸ” WORKER: Generating text...");const o=await l(e.prompt,{max_length:e.maxLength||100,temperature:e.temperature||.7,...e.options});postMessage({type:"generate-result",id:e.id,text:o[0].generated_text})}else console.log("ğŸ” WORKER: Unknown message type:",t)}catch(o){console.error("ğŸ” WORKER: Error processing message:",o),postMessage({type:"error",id:e==null?void 0:e.id,error:o.message})}});console.log("ğŸ” WORKER: Transformers.js worker ready for messages (local build)");
